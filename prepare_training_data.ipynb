{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc563fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal, stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "MOVEMENT_LIST = [\n",
    "    \"Rest\",\n",
    "    \"MassFlexion\",\n",
    "    \"HookGrasp\",\n",
    "    \"ThumbAdduction\",\n",
    "    \"PinchGrasp\",\n",
    "    \"PinchGraspMiddle\",\n",
    "    \"PinchGraspRing\",\n",
    "    \"PinchGraspPinkie\",\n",
    "    \"DiameterGrasp\",\n",
    "    \"SphereGrasp\",\n",
    "    \"MassAdduction\",\n",
    "    \"MassExtension\",\n",
    "    \"WristVolarFlexion\",\n",
    "    \"WristDorsiFlexion\",\n",
    "    \"ForearmPronation\",\n",
    "    \"ForearmSupination\",\n",
    "]\n",
    "\n",
    "MOVEMENT_COLORS = dict(zip(MOVEMENT_LIST, plt.cm.rainbow(np.linspace(0, 1, len(MOVEMENT_LIST)))))\n",
    "DATA_DIR = Path(os.getenv(\"PHYSIOMIO_DATA_DIR\", \"data\"))\n",
    "\n",
    "all_parquet_files = glob.glob(str(DATA_DIR / \"**/*.parquet\"), recursive=True)\n",
    "assert len(all_parquet_files) > 0, \"No parquet files found under data\"\n",
    "print(f\"Found {len(all_parquet_files)} parquet files under {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_channel_mean_amplitude(\n",
    "        df: pd.DataFrame,\n",
    "        channel: str,\n",
    "        movement_type_col: str = 'movement_type') -> tuple[dict[str, float], float, float]:\n",
    "    \"\"\"\n",
    "    Calculate SNR statistics for a single channel using mean amplitude.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing the EMG data and movement labels\n",
    "        channel: Name of the channel column to analyze\n",
    "        movement_type_col: Name of the column containing movement labels\n",
    "\n",
    "    Returns:\n",
    "        tuple containing:\n",
    "            - Dictionary mapping movement names to SNR values\n",
    "            - Mean SNR across all movements (excluding Rest)\n",
    "            - Standard deviation of SNR across movements\n",
    "    \"\"\"\n",
    "    unique_movements = df[movement_type_col].unique()\n",
    "    mean_amps = {}\n",
    "    snr_values = {}\n",
    "\n",
    "    # Calculate Rest mean amplitude first\n",
    "    rest_mask = df[movement_type_col] == 'Rest'\n",
    "    assert 'Rest' in unique_movements, \"Rest movement must be present in the data\"\n",
    "\n",
    "    rest_ma = df.loc[rest_mask, channel].abs().mean()\n",
    "    mean_amps['Rest'] = rest_ma\n",
    "\n",
    "    # Calculate other mean amplitudes and SNR\n",
    "    for movement in unique_movements:\n",
    "        if movement == 'Rest':\n",
    "            continue\n",
    "        mask = df[movement_type_col] == movement\n",
    "        ma = df.loc[mask, channel].abs().mean()\n",
    "        mean_amps[movement] = ma\n",
    "        # Using 20*log10 for amplitude ratio\n",
    "        snr_values[movement] = 20 * np.log10(ma / rest_ma)\n",
    "\n",
    "    # Calculate average SNR and std dev\n",
    "    snr_values_list = list(snr_values.values())\n",
    "    avg_snr = float(np.mean(snr_values_list))\n",
    "    std_snr = float(np.std(snr_values_list))\n",
    "\n",
    "    return snr_values, avg_snr, std_snr\n",
    "\n",
    "def calculate_overall_snr(df: pd.DataFrame, snr_calculator,\n",
    "                          movement_type_col: str = 'movement_type') -> tuple[float, float, list[float], float]:\n",
    "    \"\"\"\n",
    "    Calculate overall SNR across all channels\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing the EMG data and movement labels\n",
    "        snr_calculator: Function to calculate SNR statistics\n",
    "        movement_type_col: Name of the column containing movement labels\n",
    "\n",
    "    Returns:\n",
    "        tuple containing:\n",
    "            - Mean SNR across all channels and movements\n",
    "            - Standard deviation of SNR across all channels and movements\n",
    "            - List of all individual SNR values\n",
    "            - Average mean amplitude across all channels\n",
    "    \"\"\"\n",
    "    all_snr_values = []\n",
    "    all_mean_amplitudes = []\n",
    "\n",
    "    for i in range(64):\n",
    "        channel_name = f'channel_{i+1:02d}'\n",
    "        if channel_name in df.columns:\n",
    "            # Calculate SNR for this channel\n",
    "            snr_values, _, _ = snr_calculator(\n",
    "                df, channel_name, movement_type_col)\n",
    "            # Add all individual SNR values for this channel\n",
    "            all_snr_values.extend(list(snr_values.values()))\n",
    "            \n",
    "            # Calculate mean amplitude for this channel across all data\n",
    "            channel_mean_amplitude = df[channel_name].abs().mean()\n",
    "            all_mean_amplitudes.append(channel_mean_amplitude)\n",
    "\n",
    "    overall_mean_snr = float(np.mean(all_snr_values))\n",
    "    overall_std_snr = float(np.std(all_snr_values))\n",
    "    avg_mean_amplitude = float(np.mean(all_mean_amplitudes)) if all_mean_amplitudes else 0.0\n",
    "    \n",
    "    return overall_mean_snr, overall_std_snr, all_snr_values, avg_mean_amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_snrs_df(parquet_files: list[str]):\n",
    "    \"\"\"\n",
    "    Calculate detailed SNR statistics with one row per recording.\n",
    "\n",
    "    Args:\n",
    "        parquet_files: List of paths to parquet files containing EMG data\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Detailed statistics with one row per recording showing\n",
    "                     Patient, Recording, Arm Type, SNR Mean, and SNR Std Dev\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for file in tqdm(parquet_files, desc=\"Processing recordings\"):\n",
    "        # Extract patient number\n",
    "        patient_num = int(file.split('/patient')[1].split('/')[0])\n",
    "        \n",
    "        # Extract recording number from filename\n",
    "        recording_name = Path(file).stem  # Gets filename without extension\n",
    "        \n",
    "        # Determine arm type\n",
    "        if 'healthy_arm' in file:\n",
    "            arm_type = 'Healthy'\n",
    "        elif 'impaired_arm' in file:\n",
    "            arm_type = 'Impaired'\n",
    "        else:\n",
    "            arm_type = 'Unknown'\n",
    "        \n",
    "        # Calculate SNR for this recording\n",
    "        df = pd.read_parquet(file)\n",
    "        snr_mean, snr_std, _, avg_mean_amplitude = calculate_overall_snr(\n",
    "            df, snr_calculator=calculate_channel_mean_amplitude)\n",
    "        \n",
    "        rows.append({\n",
    "            'Patient': patient_num,\n",
    "            'Recording': recording_name,\n",
    "            'Arm Type': arm_type,\n",
    "            'SNR Mean (dB)': round(snr_mean, 2),\n",
    "            'SNR Std Dev (dB)': round(snr_std, 2),\n",
    "            'Avg Mean Amplitude': round(avg_mean_amplitude, 6)\n",
    "        })\n",
    "\n",
    "    # Create DataFrame and sort by Patient, then by Arm Type, then by Recording\n",
    "    df_detailed = pd.DataFrame(rows)\n",
    "    df_detailed = df_detailed.sort_values(['Patient', 'Arm Type', 'Recording'])\n",
    "    \n",
    "    return df_detailed.style.set_properties(**{'text-align': 'center'}).set_table_styles([\n",
    "        {'selector': 'th', 'props': [('text-align', 'center')]},\n",
    "        {'selector': '', 'props': [('border', '1px solid black')]},\n",
    "        {'selector': 'th,td', 'props': [('padding', '8px')]}\n",
    "    ])\n",
    "\n",
    "\n",
    "#all_snrs_df = get_patient_snrs_df(all_parquet_files)\n",
    "#display(all_snrs_df)\n",
    "\n",
    "# Display the new detailed table with one row per recording\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED SNR TABLE - ONE ROW PER RECORDING\")\n",
    "print(\"=\"*80)\n",
    "detailed_snrs_df = get_detailed_snrs_df(all_parquet_files)\n",
    "display(detailed_snrs_df)\n",
    "\n",
    "# Save the SNR table to CSV file\n",
    "snr_csv_filename = 'detailed_snrs_table.csv'\n",
    "# Convert styled DataFrame back to regular DataFrame for CSV saving\n",
    "detailed_snrs_df_plain = detailed_snrs_df.data\n",
    "detailed_snrs_df_plain.to_csv(snr_csv_filename, index=False)\n",
    "print(f\"\\nSNR table saved to: {snr_csv_filename}\")\n",
    "\n",
    "print(f\"\\nSNR analysis complete!\")\n",
    "print(f\"- Processed {len(all_parquet_files)} files\")\n",
    "print(f\"- Generated table with {len(detailed_snrs_df_plain)} recordings\")\n",
    "print(f\"- Saved detailed results to {snr_csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4b43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_emg(data: np.ndarray, fs: float) -> np.ndarray:\n",
    "    notch_freq = 50.0\n",
    "    quality_factor = 10.0\n",
    "    b_notch, a_notch = signal.iirnotch(notch_freq, quality_factor, fs)\n",
    "    filtered_data = signal.filtfilt(b_notch, a_notch, data)\n",
    "\n",
    "    high_pass_freq = 20.0\n",
    "    b_high, a_high = signal.butter(4, high_pass_freq/(fs/2), btype='high')\n",
    "    filtered_data = signal.filtfilt(b_high, a_high, filtered_data)\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def compute_psd(data: np.ndarray, fs: float, nperseg: int = 1024) -> tuple[np.ndarray, np.ndarray]:\n",
    "    nperseg = min(nperseg, len(data) // 2)\n",
    "    if nperseg < 256:\n",
    "        nperseg = 256\n",
    "\n",
    "    f, Pxx = signal.welch(data, fs, nperseg=nperseg, scaling=\"density\")\n",
    "    return f, Pxx\n",
    "\n",
    "# Fixed version of the PSD function\n",
    "def get_detailed_psd_df_fixed(parquet_files: list[str], num_freq_bins: int = 40):\n",
    "    \"\"\"\n",
    "    Calculate detailed PSD statistics with one row per recording (FIXED VERSION).\n",
    "    \n",
    "    Args:\n",
    "        parquet_files: List of paths to parquet files containing EMG data\n",
    "        num_freq_bins: Number of frequency bins to create for PSD features\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Detailed PSD statistics with one row per recording showing\n",
    "                     Patient, Recording, Arm Type, and PSD values in frequency bins\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    fs = 2048\n",
    "    \n",
    "    # Define frequency bins (20-500 Hz)\n",
    "    freq_min, freq_max = 20, 500\n",
    "    freq_bins = np.linspace(freq_min, freq_max, num_freq_bins + 1)\n",
    "    \n",
    "    # Create column names for frequency bins\n",
    "    freq_columns = []\n",
    "    for i in range(num_freq_bins):\n",
    "        freq_start = freq_bins[i]\n",
    "        freq_end = freq_bins[i + 1]\n",
    "        freq_columns.append(f'PSD_{freq_start:.1f}-{freq_end:.1f}Hz')\n",
    "    \n",
    "    for file in tqdm(parquet_files, desc=\"Processing PSD for recordings\"):\n",
    "        # Extract patient number\n",
    "        patient_num = int(file.split('/patient')[1].split('/')[0])\n",
    "        \n",
    "        # Extract recording number from filename\n",
    "        recording_name = Path(file).stem\n",
    "        \n",
    "        # Determine arm type\n",
    "        if 'healthy_arm' in file:\n",
    "            arm_type = 'Healthy'\n",
    "        elif 'impaired_arm' in file:\n",
    "            arm_type = 'Impaired'\n",
    "        else:\n",
    "            arm_type = 'Unknown'\n",
    "        \n",
    "        # Read data and calculate PSD for all channels\n",
    "        df = pd.read_parquet(file)\n",
    "        channel_psds = []\n",
    "        \n",
    "        for channel in df.columns:\n",
    "            if channel.startswith('channel_') and channel != 'channel_49':\n",
    "                channel_data = df[channel].values * 0.001\n",
    "                processed_emg = preprocess_emg(channel_data, fs)\n",
    "                f, Pxx = compute_psd(processed_emg, fs, nperseg=1024)\n",
    "                channel_psds.append(Pxx)  # Just store PSD, f is same for all\n",
    "        \n",
    "        if not channel_psds:\n",
    "            continue\n",
    "            \n",
    "        # Get frequency array (same for all channels)\n",
    "        channel_data_temp = df[df.columns[df.columns.str.startswith('channel_')][0]].values * 0.001\n",
    "        processed_temp = preprocess_emg(channel_data_temp, fs)\n",
    "        frequencies, _ = compute_psd(processed_temp, fs, nperseg=1024)\n",
    "        \n",
    "        # Average PSD across all channels for this recording\n",
    "        avg_psd = np.mean(channel_psds, axis=0)\n",
    "        \n",
    "        # Calculate power in each frequency bin\n",
    "        psd_features = {}\n",
    "        for i, col_name in enumerate(freq_columns):\n",
    "            freq_start = freq_bins[i]\n",
    "            freq_end = freq_bins[i + 1]\n",
    "            \n",
    "            # Find indices for this frequency range\n",
    "            freq_mask = (frequencies >= freq_start) & (frequencies < freq_end)\n",
    "            \n",
    "            if np.any(freq_mask):\n",
    "                # Calculate average power in this frequency bin\n",
    "                bin_power = np.mean(avg_psd[freq_mask])\n",
    "                psd_features[col_name] = bin_power  # Keep full precision\n",
    "            else:\n",
    "                psd_features[col_name] = 0.0\n",
    "        \n",
    "        # Create row with basic info and PSD features\n",
    "        row = {\n",
    "            'Patient': patient_num,\n",
    "            'Recording': recording_name,\n",
    "            'Arm Type': arm_type,\n",
    "        }\n",
    "        row.update(psd_features)\n",
    "        rows.append(row)\n",
    "    \n",
    "    # Create DataFrame and sort\n",
    "    df_psd = pd.DataFrame(rows)\n",
    "    df_psd = df_psd.sort_values(['Patient', 'Arm Type', 'Recording'])\n",
    "    \n",
    "    return df_psd\n",
    "\n",
    "\n",
    "# Test the fixed function with just a few files\n",
    "print(\"\\\\n\" + \"=\"*80)\n",
    "print(\"TESTING FIXED PSD FUNCTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_files = all_parquet_files[:3]  # Just test with 3 files\n",
    "psd_df_fixed = get_detailed_psd_df_fixed(test_files, num_freq_bins=10)  # Fewer bins for testing\n",
    "\n",
    "print(f\"Fixed PSD table shape: {psd_df_fixed.shape}\")\n",
    "print(f\"\\\\nPSD columns: {[col for col in psd_df_fixed.columns if col.startswith('PSD_')]}\")\n",
    "\n",
    "# Show the actual values with full precision\n",
    "print(\"\\\\nFirst row PSD values (showing actual numbers):\")\n",
    "first_row = psd_df_fixed.iloc[0]\n",
    "for col in psd_df_fixed.columns:\n",
    "    if col.startswith('PSD_'):\n",
    "        print(f\"  {col}: {first_row[col]:.8e}\")\n",
    "\n",
    "# Display the table\n",
    "display(psd_df_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc634260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PSD table for the whole dataset\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CALCULATING PSD TABLE FOR WHOLE DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use 20 frequency bins to balance detail vs computational efficiency\n",
    "psd_df_complete = get_detailed_psd_df_fixed(all_parquet_files, num_freq_bins=20)\n",
    "\n",
    "print(f\"Complete PSD table shape: {psd_df_complete.shape}\")\n",
    "print(f\"Number of recordings processed: {len(psd_df_complete)}\")\n",
    "\n",
    "# Display basic statistics about the table\n",
    "print(f\"\\nDataset breakdown:\")\n",
    "print(f\"- Total recordings: {len(psd_df_complete)}\")\n",
    "print(f\"- Healthy arm recordings: {len(psd_df_complete[psd_df_complete['Arm Type'] == 'Healthy'])}\")\n",
    "print(f\"- Impaired arm recordings: {len(psd_df_complete[psd_df_complete['Arm Type'] == 'Impaired'])}\")\n",
    "print(f\"- Number of patients: {psd_df_complete['Patient'].nunique()}\")\n",
    "\n",
    "# Show frequency bin columns\n",
    "psd_columns = [col for col in psd_df_complete.columns if col.startswith('PSD_')]\n",
    "print(f\"\\nFrequency bins created: {len(psd_columns)}\")\n",
    "print(\"Frequency ranges:\")\n",
    "for i, col in enumerate(psd_columns):\n",
    "    print(f\"  {i+1:2d}. {col}\")\n",
    "\n",
    "# Display the table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED PSD TABLE - ALL RECORDINGS\")\n",
    "print(\"=\"*80)\n",
    "display(psd_df_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c96fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PSD table to CSV file\n",
    "psd_csv_filename = 'detailed_psd_table.csv'\n",
    "psd_df_complete.to_csv(psd_csv_filename, index=False)\n",
    "print(f\"\\nPSD table saved to: {psd_csv_filename}\")\n",
    "\n",
    "# Show summary statistics for the PSD data\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"PSD DATA SUMMARY STATISTICS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Calculate summary statistics for each frequency bin, split by arm type\n",
    "summary_stats = []\n",
    "for col in psd_columns:\n",
    "    healthy_values = psd_df_complete[psd_df_complete['Arm Type'] == 'Healthy'][col]\n",
    "    impaired_values = psd_df_complete[psd_df_complete['Arm Type'] == 'Impaired'][col]\n",
    "    \n",
    "    summary_stats.append({\n",
    "        'Frequency_Range': col.replace('PSD_', ''),\n",
    "        'Healthy_Mean': f\"{healthy_values.mean():.2e}\",\n",
    "        'Healthy_Std': f\"{healthy_values.std():.2e}\",\n",
    "        'Impaired_Mean': f\"{impaired_values.mean():.2e}\",\n",
    "        'Impaired_Std': f\"{impaired_values.std():.2e}\",\n",
    "        'Ratio_Impaired/Healthy': f\"{impaired_values.mean()/healthy_values.mean():.3f}\"\n",
    "    })\n",
    "\n",
    "psd_summary_df = pd.DataFrame(summary_stats)\n",
    "display(psd_summary_df)\n",
    "\n",
    "print(f\"\\nPSD analysis complete!\")\n",
    "print(f\"- Processed {len(all_parquet_files)} files\")\n",
    "print(f\"- Generated table with {len(psd_df_complete)} recordings\")\n",
    "print(f\"- Created {len(psd_columns)} frequency bins from 20-500 Hz\")\n",
    "print(f\"- Saved detailed results to {psd_csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69efa6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FMA scores table\n",
    "def get_detailed_fma_df(parquet_files: list[str]):\n",
    "    \"\"\"\n",
    "    Extract FMA scores with one row per recording.\n",
    "    \n",
    "    Args:\n",
    "        parquet_files: List of paths to parquet files containing EMG data\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Detailed FMA scores with one row per recording showing\n",
    "                     Patient, Recording, Arm Type, and Average FMA Score\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for file in tqdm(parquet_files, desc=\"Processing FMA scores\"):\n",
    "        # Extract patient number\n",
    "        patient_num = int(file.split('/patient')[1].split('/')[0])\n",
    "        \n",
    "        # Extract recording number from filename\n",
    "        recording_name = Path(file).stem\n",
    "        \n",
    "        # Determine arm type\n",
    "        if 'healthy_arm' in file:\n",
    "            arm_type = 'Healthy'\n",
    "        elif 'impaired_arm' in file:\n",
    "            arm_type = 'Impaired'\n",
    "        else:\n",
    "            arm_type = 'Unknown'\n",
    "        \n",
    "        # Read data and extract FMA score\n",
    "        df = pd.read_parquet(file)\n",
    "        \n",
    "        # Calculate average FMA score for this recording (excluding NaN values)\n",
    "        fma_values = df['fma'].dropna()\n",
    "        if len(fma_values) > 0:\n",
    "            avg_fma = fma_values.mean()\n",
    "        else:\n",
    "            avg_fma = None  # No FMA data available\n",
    "        \n",
    "        rows.append({\n",
    "            'Patient': patient_num,\n",
    "            'Recording': recording_name,\n",
    "            'Arm Type': arm_type,\n",
    "            'Average FMA Score': round(avg_fma, 2) if avg_fma is not None else None\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame and sort\n",
    "    df_fma = pd.DataFrame(rows)\n",
    "    df_fma = df_fma.sort_values(['Patient', 'Arm Type', 'Recording'])\n",
    "    \n",
    "    return df_fma\n",
    "\n",
    "# Calculate FMA scores table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CALCULATING FMA SCORES TABLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fma_df = get_detailed_fma_df(all_parquet_files)\n",
    "\n",
    "print(f\"FMA scores table shape: {fma_df.shape}\")\n",
    "print(f\"Number of recordings processed: {len(fma_df)}\")\n",
    "\n",
    "# Display basic statistics about the FMA scores\n",
    "print(f\"\\nDataset breakdown:\")\n",
    "print(f\"- Total recordings: {len(fma_df)}\")\n",
    "print(f\"- Healthy arm recordings: {len(fma_df[fma_df['Arm Type'] == 'Healthy'])}\")\n",
    "print(f\"- Impaired arm recordings: {len(fma_df[fma_df['Arm Type'] == 'Impaired'])}\")\n",
    "print(f\"- Number of patients: {fma_df['Patient'].nunique()}\")\n",
    "\n",
    "# Show FMA score statistics\n",
    "fma_scores_available = fma_df['Average FMA Score'].dropna()\n",
    "print(f\"\\nFMA Score Statistics:\")\n",
    "print(f\"- Recordings with FMA scores: {len(fma_scores_available)}\")\n",
    "print(f\"- Recordings without FMA scores: {len(fma_df) - len(fma_scores_available)}\")\n",
    "\n",
    "if len(fma_scores_available) > 0:\n",
    "    print(f\"- Mean FMA score: {fma_scores_available.mean():.2f}\")\n",
    "    print(f\"- Min FMA score: {fma_scores_available.min():.2f}\")\n",
    "    print(f\"- Max FMA score: {fma_scores_available.max():.2f}\")\n",
    "    print(f\"- Std FMA score: {fma_scores_available.std():.2f}\")\n",
    "\n",
    "# Display the table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED FMA SCORES TABLE - ALL RECORDINGS\")\n",
    "print(\"=\"*80)\n",
    "display(fma_df)\n",
    "\n",
    "# Save the FMA table to CSV file\n",
    "fma_csv_filename = 'detailed_fma_table.csv'\n",
    "fma_df.to_csv(fma_csv_filename, index=False)\n",
    "print(f\"\\nFMA scores table saved to: {fma_csv_filename}\")\n",
    "\n",
    "print(f\"\\nFMA analysis complete!\")\n",
    "print(f\"- Processed {len(all_parquet_files)} files\")\n",
    "print(f\"- Generated table with {len(fma_df)} recordings\")\n",
    "print(f\"- Saved detailed results to {fma_csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0003fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CCN (Correlation Coefficient of Normality) table\n",
    "def calculate_ccn(data: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Correlation Coefficient of Normality (CCN).\n",
    "    \n",
    "    CCN is the Pearson correlation between the histogram of EMG signal amplitudes \n",
    "    and a normal distribution with the same mean and variance.\n",
    "    A CCN close to 1 indicates the signal's amplitude distribution is near-Gaussian.\n",
    "    \n",
    "    Args:\n",
    "        data: EMG signal data\n",
    "        \n",
    "    Returns:\n",
    "        CCN value (correlation coefficient)\n",
    "    \"\"\"\n",
    "    hist, bin_edges = np.histogram(data, bins='auto', density=True)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    normal_pdf = stats.norm.pdf(bin_centers, mean, std)\n",
    "\n",
    "    return np.corrcoef(hist, normal_pdf)[0, 1]\n",
    "\n",
    "\n",
    "def get_detailed_ccn_df(parquet_files: list[str]):\n",
    "    \"\"\"\n",
    "    Calculate detailed CCN statistics with one row per recording.\n",
    "    \n",
    "    Args:\n",
    "        parquet_files: List of paths to parquet files containing EMG data\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Detailed CCN statistics with one row per recording showing\n",
    "                     Patient, Recording, Arm Type, and Average CCN across all channels\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for file in tqdm(parquet_files, desc=\"Processing CCN for recordings\"):\n",
    "        # Extract patient number\n",
    "        patient_num = int(file.split('/patient')[1].split('/')[0])\n",
    "        \n",
    "        # Extract recording number from filename\n",
    "        recording_name = Path(file).stem\n",
    "        \n",
    "        # Determine arm type\n",
    "        if 'healthy_arm' in file:\n",
    "            arm_type = 'Healthy'\n",
    "        elif 'impaired_arm' in file:\n",
    "            arm_type = 'Impaired'\n",
    "        else:\n",
    "            arm_type = 'Unknown'\n",
    "        \n",
    "        # Read data and calculate CCN for all channels\n",
    "        df = pd.read_parquet(file)\n",
    "        channel_ccns = []\n",
    "        \n",
    "        for channel in df.columns:\n",
    "            if channel.startswith('channel_'):\n",
    "                signal_data = df[channel].values\n",
    "                ccn = calculate_ccn(signal_data)\n",
    "                channel_ccns.append(ccn)\n",
    "        \n",
    "        # Calculate average CCN across all channels for this recording\n",
    "        if channel_ccns:\n",
    "            avg_ccn = np.mean(channel_ccns)\n",
    "            std_ccn = np.std(channel_ccns)\n",
    "        else:\n",
    "            avg_ccn = None\n",
    "            std_ccn = None\n",
    "        \n",
    "        rows.append({\n",
    "            'Patient': patient_num,\n",
    "            'Recording': recording_name,\n",
    "            'Arm Type': arm_type,\n",
    "            'Average CCN': round(avg_ccn, 4) if avg_ccn is not None else None,\n",
    "            'CCN Std Dev': round(std_ccn, 4) if std_ccn is not None else None\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame and sort\n",
    "    df_ccn = pd.DataFrame(rows)\n",
    "    df_ccn = df_ccn.sort_values(['Patient', 'Arm Type', 'Recording'])\n",
    "    \n",
    "    return df_ccn\n",
    "\n",
    "\n",
    "# Calculate CCN table for the whole dataset\n",
    "print(\"\\\\n\" + \"=\"*80)\n",
    "print(\"CALCULATING CCN TABLE FOR WHOLE DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "ccn_df = get_detailed_ccn_df(all_parquet_files)\n",
    "\n",
    "print(f\"CCN table shape: {ccn_df.shape}\")\n",
    "print(f\"Number of recordings processed: {len(ccn_df)}\")\n",
    "\n",
    "# Display basic statistics about the CCN values\n",
    "print(f\"\\\\nDataset breakdown:\")\n",
    "print(f\"- Total recordings: {len(ccn_df)}\")\n",
    "print(f\"- Healthy arm recordings: {len(ccn_df[ccn_df['Arm Type'] == 'Healthy'])}\")\n",
    "print(f\"- Impaired arm recordings: {len(ccn_df[ccn_df['Arm Type'] == 'Impaired'])}\")\n",
    "print(f\"- Number of patients: {ccn_df['Patient'].nunique()}\")\n",
    "\n",
    "# Show CCN statistics\n",
    "ccn_values_available = ccn_df['Average CCN'].dropna()\n",
    "print(f\"\\\\nCCN Statistics:\")\n",
    "print(f\"- Recordings with CCN values: {len(ccn_values_available)}\")\n",
    "\n",
    "if len(ccn_values_available) > 0:\n",
    "    print(f\"- Mean CCN: {ccn_values_available.mean():.4f}\")\n",
    "    print(f\"- Min CCN: {ccn_values_available.min():.4f}\")\n",
    "    print(f\"- Max CCN: {ccn_values_available.max():.4f}\")\n",
    "    print(f\"- Std CCN: {ccn_values_available.std():.4f}\")\n",
    "    \n",
    "    # Compare healthy vs impaired\n",
    "    healthy_ccn = ccn_df[ccn_df['Arm Type'] == 'Healthy']['Average CCN'].dropna()\n",
    "    impaired_ccn = ccn_df[ccn_df['Arm Type'] == 'Impaired']['Average CCN'].dropna()\n",
    "    \n",
    "    if len(healthy_ccn) > 0 and len(impaired_ccn) > 0:\n",
    "        print(f\"\\\\nComparison by Arm Type:\")\n",
    "        print(f\"- Healthy arm mean CCN: {healthy_ccn.mean():.4f} ± {healthy_ccn.std():.4f}\")\n",
    "        print(f\"- Impaired arm mean CCN: {impaired_ccn.mean():.4f} ± {impaired_ccn.std():.4f}\")\n",
    "\n",
    "# Display the table\n",
    "print(\"\\\\n\" + \"=\"*80)\n",
    "print(\"DETAILED CCN TABLE - ALL RECORDINGS\")\n",
    "print(\"=\"*80)\n",
    "display(ccn_df)\n",
    "\n",
    "# Save the CCN table to CSV file\n",
    "ccn_csv_filename = 'detailed_ccn_table.csv'\n",
    "ccn_df.to_csv(ccn_csv_filename, index=False)\n",
    "print(f\"\\\\nCCN table saved to: {ccn_csv_filename}\")\n",
    "\n",
    "print(f\"\\\\nCCN analysis complete!\")\n",
    "print(f\"- Processed {len(all_parquet_files)} files\")\n",
    "print(f\"- Generated table with {len(ccn_df)} recordings\")\n",
    "print(f\"- Saved detailed results to {ccn_csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4275b115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
